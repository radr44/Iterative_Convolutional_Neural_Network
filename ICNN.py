# -*- coding: utf-8 -*-
"""icnn_fwdprop.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13O4tya8xLTce0DqXL9d8ziNhC0fc5rxZ
"""

import cv2 as cv
import torch
import numpy as np
import pywt
import subsampling
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import preprocessing

class micro_cnn_Alexnet(nn.Module):
  def __init__(self,k=0,nfc=128,threshold=0.6):
    super(micro_cnn_Alexnet, self).__init__()
    #k is the f_map count

    self.k = k
    self.nfc = nfc
    self.threshold = threshold
 

    self.conv1b = nn.Conv2d(3,18,5,padding=2)
    self.conv2 = nn.Conv2d(18,48,5,padding=2)
    self.conv3 = nn.Conv2d(48,64,3,padding=1)
    self.conv4 = nn.Conv2d(64,32,3,padding=1)
    self.conv5 = nn.Conv2d(32,32,3,padding=1)

    self.fc1 = nn.Linear((32*(self.k+1))*6*9,2*self.nfc)
    self.fc2 = nn.Linear(2*self.nfc,self.nfc)
    self.fc3 = nn.Linear(self.nfc,15)

  def forward(self, x, time = 0, n = 0, n_max = 10, fmaps=None, t_max = float('inf'),policy="DyanamicDeadlinePolicy"):
    if policy=="DyanamicDeadlinePolicy":
      x = F.relu(self.conv1b(x))
  
      x = F.max_pool2d(x, 2, 2)
      x = F.relu(self.conv2(x))
      x = F.max_pool2d(x, 2, 2)
      x = F.relu(self.conv3(x))
      x = F.relu(self.conv4(x))
      x = F.relu(self.conv5(x))
      x = F.max_pool2d(x, 2, 2)
      if fmaps is None:
        fmaps = x
      else:  
        fmaps = torch.cat((fmaps,x), dim=1)
    
      if time>t_max or n==n_max:
     
        x = fmaps.view(-1,32*(1+self.k)*6*9) 
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

      else:
        return fmaps  
    
    elif policy == "ThresholdingPolicy":
      x = F.relu(self.conv1b(x))
  
      x = F.max_pool2d(x, 2, 2)
      x = F.relu(self.conv2(x))
      x = F.max_pool2d(x, 2, 2)
      x = F.relu(self.conv3(x))
      x = F.relu(self.conv4(x))
      x = F.relu(self.conv5(x))
      fmaps_curr = F.max_pool2d(x, 2, 2)
      x = fmaps_curr.view(-1,32*(1+self.k)*6*9) 
      x = F.relu(self.fc1(x))
      x = F.relu(self.fc2(x))
      x = self.fc3(x)
      best=torch.max(x)
      if n==n_max:
        return 0,x
      elif best>self.threshold:
        return 0,x
      elif fmaps is None:
        fmaps = fmaps_curr
        return 1,fmaps
      else:  
        fmaps = torch.cat((fmaps,fmaps_curr), dim=1)
        return 1,fmaps

class ICNN_Alexnet(nn.Module):
  def __init__(self, ucnn, t_max=float('inf'), n_max=6, batch_size=4, policy ='DyanamicDeadlinePolicy'):
    super(ICNN_Alexnet, self).__init__()

    self.n_max = n_max
    self.t_max = t_max
    self.batch_size = batch_size 
    self.ucnn = nn.ModuleList(ucnn)
    self.policy = policy

  def forward(self, x):
    if self.policy=="DyanamicDeadlinePolicy":
       temp = time.time() 
       output_f = None
       for i,microcnn in enumerate(self.ucnn):
         if i == self.n_max:
           break
         input_f = preprocessing.prepare_batch(x,i,self.batch_size)
         output_f = microcnn(input_f, time=temp, n=i+1, n_max=self.n_max, fmaps=output_f, t_max=self.t_max)
      
         if temp>self.t_max: 
           return output_f
       return output_f  

    elif self.policy =='ThresholdingPolicy': 
      output_f = None
      for i,microcnn in enumerate(self.ucnn):
         input_f = preprocessing.prepare_batch(x,i,self.batch_size)
         repeat,output_f = microcnn(input_f.type(torch.float32), time=temp, n=i+1, n_max=self.n_max, fmaps=output_f, t_max=self.t_max)
         if repeat==0:
           return output_f
      return output_f